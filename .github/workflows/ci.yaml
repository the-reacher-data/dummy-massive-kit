name: CI

on:
  push:
    branches: ["feature/**", "multifeature/**", "fix/**", "hotfix/**", "chore/**", "docs/**"]
  pull_request:
    branches: ["main"]

env:
  PYTHON_VERSION: "3.11"

jobs:
  quality:
    runs-on: ubuntu-latest
    outputs:
      tests: ${{ steps.pytest.outputs.results }}
      coverage: ${{ steps.pytest.outputs.coverage }}
      lint: ${{ steps.lint.outputs.errors }}
      types: ${{ steps.types.outputs.errors }}
      bandit: ${{ steps.bandit.outputs.issues }}
      snyk: ${{ steps.snyk.outputs.issues }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: astral-sh/setup-uv@v3

      - run: uv sync --group ci

      - id: lint
        run: |
          if uv run ruff check . > lint.log 2>&1; then
            echo "errors=0" >> $GITHUB_OUTPUT
          else
            ERR=$(grep -c "error" lint.log || echo "1")
            echo "errors=$ERR" >> $GITHUB_OUTPUT
            exit 1
          fi

      - id: types
        run: |
          if uv run mypy src > types.log 2>&1; then
            echo "errors=0" >> $GITHUB_OUTPUT
          else
            ERR=$(grep -c "error:" types.log || echo "1")
            echo "errors=$ERR" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: üß™ Install Test Dependencies
        run: |
          # Sync dependencies from pyproject.toml (ci + dev groups)
          uv sync --group ci --group dev

          # Verify pytest and coverage are available
          uv run pytest --version
          uv run coverage --version

          # Create .coveragerc for consistent coverage
          cat > .coveragerc << 'EOF'
        shell: bash

      - name: üß™ Run Tests with Coverage
        id: pytest
        run: |
          # Set up environment for module discovery
          export PYTHONPATH=src/

          # Run pytest with full coverage and reporting
          uv run pytest src/tests/ \
            --cov=src \
            --cov-config=.coveragerc \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-branch \
            --junit-xml=pytest.xml \
            --cov-fail-under=85 \
            -v \
            --tb=short \
            2>&1 | tee pytest.log || {
              echo "‚ùå Pytest failed - see output above"
              cat pytest.log
              exit 1
            }

          # Verify reports were generated
          if [ ! -f coverage.xml ]; then
            echo "‚ùå coverage.xml not generated"
            ls -la *.xml || true
            exit 1
          fi

          if [ ! -f pytest.xml ]; then
            echo "‚ùå pytest.xml (JUnit) not generated"
            ls -la *.xml || true
            exit 1
          fi

          # Extract coverage percentage using coverage CLI (most reliable)
          if uv run coverage report --total 2>/dev/null | tail -1 | grep -q "TOTAL"; then
            COVERAGE=$(uv run coverage report --total | tail -1 | awk '{print $NF}' | sed 's/%//')
          else
            # Fallback: parse the term-missing report from pytest output
            COVERAGE=$(grep -oP 'TOTAL.*\K\d+%' pytest.log | head -1 | sed 's/%//' || echo "0")
          fi

          echo "coverage=${COVERAGE}" >> $GITHUB_OUTPUT
          echo "üìà Coverage: ${COVERAGE}%"

          # Extract test results from pytest output (robust parsing)
          if grep -q "collected" pytest.log; then
            TESTS_COLLECTED=$(grep -oP 'collected \K\d+' pytest.log | head -1 || echo "0")
            TESTS_PASSED=$(grep -oP '\d+(?= passed)' pytest.log | tail -1 || echo "0")
            TESTS_FAILED=$(grep -oP '\d+(?= failed)' pytest.log | tail -1 || echo "0")
            TESTS_SKIPPED=$(grep -oP '\d+(?= skipped)' pytest.log | tail -1 || echo "0")
            TOTAL_TESTS=$((TESTS_COLLECTED))
          else
            TESTS_COLLECTED=0
            TESTS_PASSED=0
            TESTS_FAILED=0
            TESTS_SKIPPED=0
            TOTAL_TESTS=0
          fi

          echo "results=${TESTS_PASSED}/${TOTAL_TESTS}" >> $GITHUB_OUTPUT
          echo "Tests: ${TESTS_PASSED} passed, ${TESTS_FAILED} failed"

          # Fail if tests failed or coverage below threshold
          if [ "$TESTS_FAILED" -gt 0 ]; then
            echo "‚ùå ${TESTS_FAILED} tests failed"
            exit 1
          fi

          if [ $(echo "${COVERAGE} < 85" | bc -l) ]; then
            echo "‚ùå Coverage below 85%: ${COVERAGE}%"
            uv run coverage html  # Generate HTML for debugging
            exit 1
          fi

          echo "‚úÖ All tests passed with ${COVERAGE}% coverage!"
        shell: bash

      - name: üìä Upload Coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true
        if: always()

      - name: üì¶ Upload Test Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: test-reports
          path: |
            coverage.xml
            pytest.xml
            pytest.log
            .coverage
            htmlcov/
          retention-days: 30
        if: always()

      - name: üìã Test Summary
        id: test-summary
        run: |
          if [ -f pytest.xml ]; then
            # Parse JUnit XML for test counts (fallback to log if xmlstarlet not available)
            if command -v xmlstarlet &> /dev/null; then
              PASSED=$(xmlstarlet sel -t -v "//testcase[count(failure)=0]" pytest.xml 2>/dev/null | wc -l || echo "0")
              FAILED=$(xmlstarlet sel -t -v "//testcase/failure" pytest.xml 2>/dev/null | wc -l || echo "0")
              SKIPPED=$(xmlstarlet sel -t -v "//testcase/skipped" pytest.xml 2>/dev/null | wc -l || echo "0")
            else
              # Fallback: parse pytest log
              PASSED=$(grep -c " PASSED " pytest.log 2>/dev/null || echo "0")
              FAILED=$(grep -c " FAILED " pytest.log 2>/dev/null || echo "0")
              SKIPPED=$(grep -c " SKIPPED " pytest.log 2>/dev/null || echo "0")
            fi
            TOTAL=$((PASSED + FAILED + SKIPPED))
          else
            PASSED=0
            FAILED=0
            SKIPPED=0
            TOTAL=0
          fi

          echo "results=${PASSED}/${TOTAL} (${SKIPPED} skipped)" >> $GITHUB_OUTPUT
          echo "Tests: ${PASSED} passed, ${FAILED} failed, ${SKIPPED} skipped"

          if [ "$FAILED" -gt 0 ]; then
            echo "‚ùå ${FAILED} tests failed"
            exit 1
          fi
        shell: bash

      - id: bandit
        run: |
          if uv run bandit -r src -f json -o bandit.json; then
            echo "issues=0" >> $GITHUB_OUTPUT
          else
            COUNT=$(jq '.results | length' bandit.json || echo 1)
            echo "issues=$COUNT" >> $GITHUB_OUTPUT
          fi

      - id: snyk
        uses: snyk/actions/python@master
        continue-on-error: true
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --json-file-output=snyk.json
          run: |
            COUNT=$(jq '.vulnerabilities | length' snyk.json || echo 0)
            echo "issues=$COUNT" >> $GITHUB_OUTPUT

      - uses: codecov/codecov-action@v4
        if: github.event_name == 'pull_request'
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          fail_ci_if_error: false

      - uses: actions/upload-artifact@v4
        with:
          name: ci-artifacts
          path: |
            pytest.log
            coverage.xml
            lint.log
            types.log
            bandit.json
            snyk.json

  prerelease:
    runs-on: ubuntu-latest
    needs: quality
    if: |
      needs.quality.result == 'success' &&
      (startsWith(github.ref, 'refs/heads/feature/') ||
       startsWith(github.ref, 'refs/heads/multifeature/') ||
       startsWith(github.ref, 'refs/heads/fix/') ||
       startsWith(github.ref, 'refs/heads/hotfix/') ||
       github.event_name == 'pull_request')
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: astral-sh/setup-uv@v3
      - run: uv sync --group build
      - name: Dry-run semantic-release
        id: semrel
        uses: cycjimmy/semantic-release-action@v4
        with:
          semantic_version: 20
          extra_plugins: |
            @semantic-release/changelog
            @semantic-release/git
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true
      - run: |
          echo "Next version (predicted): ${{ steps.semrel.outputs.new_release_version }}"

  pr-comment:
    runs-on: ubuntu-latest
    needs: [quality, prerelease]
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/github-script@v7
        with:
          script: |
            const tests = "${{ needs.quality.outputs.tests }}";
            const cov = "${{ needs.quality.outputs.coverage }}";
            const lint = "${{ needs.quality.outputs.lint }}";
            const types = "${{ needs.quality.outputs.types }}";
            const bandit = "${{ needs.quality.outputs.bandit }}";
            const snyk = "${{ needs.quality.outputs.snyk }}";
            const version = "${{ needs.prerelease.outputs.new_release_version || 'n/a' }}";
            const body = `
            ## üéØ CI/CD Summary
            - **Tests**: ${tests} (coverage ${cov}%)
            - **Lint errors**: ${lint}
            - **Type errors**: ${types}
            - **Bandit issues**: ${bandit}
            - **Snyk vulnerabilities**: ${snyk}
            - **Next version (predicted)**: ${version}
            `;
            const {owner, repo} = context.repo;
            const issue_number = context.issue.number;
            const comments = await github.rest.issues.listComments({owner, repo, issue_number});
            const existing = comments.data.find(c => c.body.includes("## üéØ CI/CD Summary"));
            if (existing) {
              await github.rest.issues.updateComment({owner, repo, comment_id: existing.id, body});
            } else {
              await github.rest.issues.createComment({owner, repo, issue_number, body});
            }
